{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras to implement a 1D convolutional neural network (CNN) for timeseries prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the 1D CNN\n",
    "\n",
    "We create a simple convolutional neural network: a 1D convolutional layer, followed by a dense layer.\n",
    "\n",
    "It will allow us to predict the next value in a timeseries given an input sequence of length `window_size`\n",
    "\n",
    "The `filter_length` is the length (in time-steps) of the sliding window that gets convolved with each position along each instance. The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed to the number of input timeseries (its \"width\" being `filter_length`), and it can only slide along the window dimension.  This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n",
    "`nb_filter` is the number of such filters to learn (roughly, input patterns to recognize).\n",
    "\n",
    "The model can handle multivariate timeseries (with `nb_input_series` variables) and multiple (`nb_outputs`) prediction targets. Predicting future values of a timeseries means setting these equal to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_CNN(window_size, filter_length,  nb_filter=4, nb_input_series=1, nb_outputs=1):\n",
    "    \"\"\"\n",
    "    window_size (int): number of observations in each input sequence\n",
    "    filter length (int): length of the convolutional layer's filters\n",
    "    nb_filter (int): number of filters learned in the convolutional layer\n",
    "    nb_input_series (int): number of features of the input timeseries (1 for a univariate timeseries)\n",
    "    nb_outputs (int): number of features being predicted (equal to nb_input_series \n",
    "        for predicting a timeseries at a set horizon)\n",
    "    \"\"\"\n",
    "    model = Sequential((\n",
    "        # The convolutional layer learns `nb_filter` filters (aka kernels), \n",
    "        # each of size `(filter_length, nb_input_series)`.  \n",
    "        # Its output will have shape `(None, window_size - filter_length + 1, nb_filter)` ,  \n",
    "        # i.e., for each position in the input timeseries, the activation of each filter at that position.\n",
    "        Conv1D(filters=nb_filter, kernel_size=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n",
    "        Flatten(),\n",
    "        Dense(nb_outputs, activation='linear'), # For classification, a 'sigmoid' activation function would be used\n",
    "    ))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = make_CNN(window_size=50, filter_length=5, nb_filter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (None, 50, 1)\n",
      "output shape: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "print('input shape:', CNN_model.layers[0].input_shape)\n",
    "print('output shape:', CNN_model.layers[-1].output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "  \n",
    "We define a function to format a timeseries for training the neural network. It creates corresponding arrays of input sequences `X` and output values `y`. They have the same length as each other; the remaining dimensions must match the input and output layers of the model respectively:\n",
    "\n",
    "The `X` input to the model's `fit()` method should be a 3D array of shape `(n_instances, window_size, n_ts_variables)`; each instance being a 2D array of shape `(window_size, nb_input_series)`.  For example, for `window_size = 3` and `nb_input_series = 1` (a univariate timeseries), one instance could be `[[0], [1], [2]]`\n",
    "\n",
    "For each input instance, the output is a vector of size `nb_outputs`, usually the value(s) predicted to come after the last value in that input instance, i.e., the next value in the sequence. The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_instances(timeseries, window_size):\n",
    "    # Convert 1D vectors to 2D column vectors\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T \n",
    "    \n",
    "    if not 0 < window_size < timeseries.shape[0]:\n",
    "        raise ValueError('Please set 0 < window size < timeseries length')\n",
    "    \n",
    "    # `X `is the tensor containing the inputs for the model\n",
    "    # each row of `X` is a sequence of `window_size` observations from the timeseries\n",
    "    X = [timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]\n",
    "    \n",
    "    # for training the model, the array's dimensions must match the input layer of the CNN\n",
    "    # that is, a 3D array of shape (timeseries.shape[0] - window_size, window_size, nof_ts_variables)\n",
    "    X = np.atleast_3d(np.array(X))\n",
    "    \n",
    "    # For each row of `X`, the corresponding row of `y` is the \n",
    "    # desired output -- in this case, the subsequent value in the timeseries \n",
    "    y = timeseries[window_size:]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[[ 1]\n",
      "  [ 1]\n",
      "  [ 2]\n",
      "  [ 3]\n",
      "  [ 5]]\n",
      "\n",
      " [[ 1]\n",
      "  [ 2]\n",
      "  [ 3]\n",
      "  [ 5]\n",
      "  [ 8]]\n",
      "\n",
      " [[ 2]\n",
      "  [ 3]\n",
      "  [ 5]\n",
      "  [ 8]\n",
      "  [13]]]\n",
      "y:\n",
      "[[ 8]\n",
      " [13]\n",
      " [21]]\n"
     ]
    }
   ],
   "source": [
    "X_fib, y_fib = make_timeseries_instances([1,1,2,3,5,8,13,21], 5)\n",
    "print('X:', X_fib, 'y:', y_fib, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a toy timeseries and split it for training and testing the CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = np.arange(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_timeseries_instances(timeseries, window_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input instance:\n",
      " [[42]\n",
      " [43]\n",
      " [44]\n",
      " ...\n",
      " [89]\n",
      " [90]\n",
      " [91]]\n",
      "output instance:\n",
      " [92]\n"
     ]
    }
   ],
   "source": [
    "i = 42\n",
    "print('input instance:\\n', X[i])\n",
    "print('output instance:\\n', y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.01 # In real life you'd usually want to use 0.2 - 0.5\n",
    "test_size = int(test_ratio * len(timeseries)) \n",
    "\n",
    "# the \"most recent\" values are used for testing the model to avoid look-ahead bias\n",
    "X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the dimensions of the arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(940, 50, 1), (10, 50, 1), (940, 1), (10, 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in [X_train, X_test, y_train, y_test]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model. Note that `validation_data` is not used to train the model, but allows you to monitor its out-of-sample performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "470/470 [==============================] - 1s 2ms/step - loss: 16740.5469 - mae: 46.4798 - val_loss: 299.5902 - val_mae: 17.3082\n",
      "Epoch 2/25\n",
      "470/470 [==============================] - 0s 1ms/step - loss: 170.3173 - mae: 10.9078 - val_loss: 299.3968 - val_mae: 17.3026\n",
      "Epoch 3/25\n",
      "470/470 [==============================] - 0s 1ms/step - loss: 163.8192 - mae: 10.7058 - val_loss: 0.7895 - val_mae: 0.8850\n",
      "Epoch 4/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 162.5488 - mae: 10.6953 - val_loss: 77.6748 - val_mae: 8.8128\n",
      "Epoch 5/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 150.5237 - mae: 10.3666 - val_loss: 545.6761 - val_mae: 23.3593\n",
      "Epoch 6/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 150.3295 - mae: 10.4109 - val_loss: 0.9453 - val_mae: 0.9702\n",
      "Epoch 7/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 125.1624 - mae: 9.3778 - val_loss: 430.2261 - val_mae: 20.7415\n",
      "Epoch 8/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 109.1511 - mae: 8.7505 - val_loss: 145.1785 - val_mae: 12.0487\n",
      "Epoch 9/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 96.3171 - mae: 8.3801 - val_loss: 6.1549 - val_mae: 2.4802\n",
      "Epoch 10/25\n",
      "470/470 [==============================] - 0s 1ms/step - loss: 91.6524 - mae: 8.0967 - val_loss: 0.3781 - val_mae: 0.6130\n",
      "Epoch 11/25\n",
      "470/470 [==============================] - 0s 1ms/step - loss: 81.0609 - mae: 7.6617 - val_loss: 113.6732 - val_mae: 10.6615\n",
      "Epoch 12/25\n",
      "470/470 [==============================] - 0s 1ms/step - loss: 55.5067 - mae: 6.2494 - val_loss: 86.3857 - val_mae: 9.2942\n",
      "Epoch 13/25\n",
      "470/470 [==============================] - 0s 1ms/step - loss: 53.9663 - mae: 6.1248 - val_loss: 66.1517 - val_mae: 8.1332\n",
      "Epoch 14/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 32.9655 - mae: 4.9115 - val_loss: 61.2033 - val_mae: 7.8231\n",
      "Epoch 15/25\n",
      "470/470 [==============================] - 0s 1ms/step - loss: 30.3040 - mae: 4.5057 - val_loss: 89.8525 - val_mae: 9.4791\n",
      "Epoch 16/25\n",
      "470/470 [==============================] - 0s 1ms/step - loss: 21.5842 - mae: 3.9352 - val_loss: 5.5978 - val_mae: 2.3658\n",
      "Epoch 17/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 27.3901 - mae: 4.1346 - val_loss: 4.0833 - val_mae: 2.0207\n",
      "Epoch 18/25\n",
      "470/470 [==============================] - 0s 1ms/step - loss: 31.1395 - mae: 4.0695 - val_loss: 42.5400 - val_mae: 6.5222\n",
      "Epoch 19/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 15.6758 - mae: 2.9767 - val_loss: 0.2631 - val_mae: 0.5128\n",
      "Epoch 20/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 7.2329 - mae: 2.2176 - val_loss: 0.2756 - val_mae: 0.5249\n",
      "Epoch 21/25\n",
      "470/470 [==============================] - 0s 1ms/step - loss: 4.8935 - mae: 1.7713 - val_loss: 3.3376 - val_mae: 1.8269\n",
      "Epoch 22/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 9.1010 - mae: 1.9991 - val_loss: 49.4777 - val_mae: 7.0340\n",
      "Epoch 23/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 4.8435 - mae: 1.5711 - val_loss: 9.2651 - val_mae: 3.0438\n",
      "Epoch 24/25\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 146.9629 - mae: 5.2853 - val_loss: 0.0428 - val_mae: 0.2068\n",
      "Epoch 25/25\n",
      "470/470 [==============================] - 0s 1ms/step - loss: 0.4242 - mae: 0.5468 - val_loss: 0.1542 - val_mae: 0.3927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15bafae6a60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model.fit(X_train, y_train, epochs=25, batch_size=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the weights of the convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 46, 4)             24        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 184)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 209\n",
      "Trainable params: 209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: conv1d_1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m CNN_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mCNN_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconv1d_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2562\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[1;34m(self, name, index)\u001b[0m\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name:\n\u001b[0;32m   2561\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[1;32m-> 2562\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo such layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2563\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProvide either a layer name or layer index.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: No such layer: conv1d_1."
     ]
    }
   ],
   "source": [
    "CNN_model.summary()\n",
    "\n",
    "CNN_model.get_layer('conv1d_1').weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with the model\n",
    "Get the predicted values for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = CNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(np.column_stack((y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple-input, multiple-output prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vars = 4\n",
    "mv_timeseries = np.array([i * np.arange(1000) for i in np.arange(1, n_vars + 1)]).T\n",
    "print(mv_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_X, mv_y = make_timeseries_instances(mv_timeseries, 50)\n",
    "\n",
    "print('X[0]: ', mv_X[0], 'y[0]:', mv_y[0], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.01 # In real life you'd usually want to use 0.2 - 0.5\n",
    "test_size = int(test_ratio * len(timeseries)) \n",
    "\n",
    "mv_X_train, mv_X_test = mv_X[:-test_size], mv_X[-test_size:] \n",
    "mv_y_train, mv_y_test = mv_y[:-test_size], mv_y[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_CNN_model = make_CNN(window_size=50, filter_length=5, nb_filter=4, nb_input_series=n_vars, nb_outputs=n_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mv_CNN_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmv_CNN_model\u001b[49m\u001b[38;5;241m.\u001b[39mfit(mv_X_train, mv_y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(mv_X_test, mv_y_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mv_CNN_model' is not defined"
     ]
    }
   ],
   "source": [
    "mv_CNN_model.fit(mv_X_train, mv_y_train, epochs=25, batch_size=2, validation_data=(mv_X_test, mv_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mv_y_pred = mv_CNN_model.predict(mv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: [ 990 1980 2970 3960] \tpred: [ 980.3531 1968.6608 2958.1584 3950.858 ]\n",
      "true: [ 991 1982 2973 3964] \tpred: [ 981.3445 1970.6503 2961.1492 3954.8552]\n",
      "true: [ 992 1984 2976 3968] \tpred: [ 982.3357 1972.6409 2964.1401 3958.8518]\n",
      "true: [ 993 1986 2979 3972] \tpred: [ 983.32697 1974.6309  2967.1316  3962.8486 ]\n",
      "true: [ 994 1988 2982 3976] \tpred: [ 984.31824 1976.621   2970.1228  3966.8457 ]\n",
      "true: [ 995 1990 2985 3980] \tpred: [ 985.3092 1978.6108 2973.1133 3970.8428]\n",
      "true: [ 996 1992 2988 3984] \tpred: [ 986.3005 1980.6011 2976.1047 3974.8394]\n",
      "true: [ 997 1994 2991 3988] \tpred: [ 987.2918 1982.591  2979.0962 3978.836 ]\n",
      "true: [ 998 1996 2994 3992] \tpred: [ 988.28284 1984.5813  2982.0872  3982.833  ]\n",
      "true: [ 999 1998 2997 3996] \tpred: [ 989.274  1986.5712 2985.0784 3986.8303]\n"
     ]
    }
   ],
   "source": [
    "for i in range(test_size):\n",
    "    print('true:', mv_y_test[i], '\\tpred:', mv_y_pred[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
